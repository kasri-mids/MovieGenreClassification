@article{HeZRS15,
  author    = {Kaiming He and
               Xiangyu Zhang and
               Shaoqing Ren and
               Jian Sun},
  title     = {Deep Residual Learning for Image Recognition},
  journal   = {CoRR},
  volume    = {abs/1512.03385},
  year      = {2015},
  url       = {http://arxiv.org/abs/1512.03385},
  archivePrefix = {arXiv},
  eprint    = {1512.03385},
  timestamp = {Wed, 17 Apr 2019 17:23:45 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/HeZRS15.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@misc{lipton2014thresholding,
    title={Thresholding Classifiers to Maximize F1 Score},
    author={Zachary Chase Lipton and Charles Elkan and Balakrishnan Narayanaswamy},
    year={2014},
    eprint={1402.1892},
    archivePrefix={arXiv},
    primaryClass={stat.ML}
}

@article{DevlinBERT,
  author    = {Jacob Devlin and
               Ming{-}Wei Chang and
               Kenton Lee and
               Kristina Toutanova},
  title     = {{BERT:} Pre-training of Deep Bidirectional Transformers for Language
               Understanding},
  journal   = {CoRR},
  volume    = {abs/1810.04805},
  year      = {2018},
  url       = {http://arxiv.org/abs/1810.04805},
  archivePrefix = {arXiv},
  eprint    = {1810.04805},
  timestamp = {Tue, 30 Oct 2018 20:39:56 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1810-04805.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{Cer2018,
  author    = {Daniel Cer and
               Yinfei Yang and
               Sheng{-}yi Kong and
               Nan Hua and
               Nicole Limtiaco and
               Rhomni St. John and
               Noah Constant and
               Mario Guajardo{-}Cespedes and
               Steve Yuan and
               Chris Tar and
               Yun{-}Hsuan Sung and
               Brian Strope and
               Ray Kurzweil},
  title     = {Universal Sentence Encoder},
  journal   = {CoRR},
  volume    = {abs/1803.11175},
  year      = {2018},
  url       = {http://arxiv.org/abs/1803.11175},
  archivePrefix = {arXiv},
  eprint    = {1803.11175},
  timestamp = {Mon, 13 Aug 2018 16:46:40 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1803-11175.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{ChuGuo2017,
author = {Chu, Wei-Ta and Guo, Hung-Jui},
title = {Movie Genre Classification Based on Poster Images with Deep Neural Networks},
year = {2017},
isbn = {9781450355094},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3132515.3132516},
doi = {10.1145/3132515.3132516},
booktitle = {Proceedings of the Workshop on Multimodal Understanding of Social, Affective and Subjective Attributes},
pages = {39–45},
numpages = {7},
keywords = {deep neural network, multi-label classification, movie poster, movie genre classification},
location = {Mountain View, California, USA},
series = {MUSA2 ’17}
}
@InProceedings{IvasicPobar2014,
author="Ivasic-Kos, Marina
and Pobar, Miran
and Ipsic, Ivo",
editor="Bogdanova, Ana Madevska
and Gjorgjevikj, Dejan",
title="Automatic Movie Posters Classification into Genres",
booktitle="ICT Innovations 2014",
year="2015",
publisher="Springer International Publishing",
address="Cham",
pages="319--328",
abstract="A person can quickly grasp the movie genre (drama, comedy, cartoons, etc.) from a poster, regardless of short observation time, clutter and variety of details. Bearing this in mind, it can be assumed that simple properties of a movie poster should play a significant role in automated detection of movie genres. Therefore, visual features based on colors and structural cues are extracted from poster images and used for poster classification into genres.",
isbn="978-3-319-09879-1"
}

@inproceedings{ZhouHermans2010,
author = {Zhou, Howard and Hermans, Tucker and Karandikar, Asmita V. and Rehg, James M.},
title = {Movie Genre Classification via Scene Categorization},
year = {2010},
isbn = {9781605589336},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1873951.1874068},
doi = {10.1145/1873951.1874068},
booktitle = {Proceedings of the 18th ACM International Conference on Multimedia},
pages = {747–750},
numpages = {4},
keywords = {video analysis, genre classification, scene understanding},
location = {Firenze, Italy},
series = {MM ’10}
}

@article{turc2019,
  title={Well-Read Students Learn Better: On the Importance of Pre-training Compact Models},
  author={Turc, Iulia and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  journal={arXiv preprint arXiv:1908.08962v2 },
  year={2019}
}

@article{wi2020, author={J. A. {Wi} and S. {Jang} and Y. {KIM}}, journal={IEEE Access}, title={Poster-based Multiple Movie Genre Classification Using Inter-Channel Features}, year={2020}, volume={}, number={}, pages={1-1},}

@inproceedings{Goldstein2007,
author = {Goldstein, Jade and Ciany, Gary M. and Carbonell, Jaime G.},
title = {Genre Identification and Goal-Focused Summarization},
year = {2007},
isbn = {9781595938039},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1321440.1321568},
doi = {10.1145/1321440.1321568},
booktitle = {Proceedings of the Sixteenth ACM Conference on Conference on Information and Knowledge Management},
pages = {889–892},
numpages = {4},
keywords = {text categorization, summarization, task-based information retrieval, metadata extraction, machine learning, genre identification, evaluation, text classification, data mining},
location = {Lisbon, Portugal},
series = {CIKM ’07}
}

@misc{hoang2018predicting,
    title={Predicting Movie Genres Based on Plot Summaries},
    author={Quan Hoang},
    year={2018},
    eprint={1801.04813},
    archivePrefix={arXiv},
    primaryClass={cs.CL}
}

@article{Chao2016AutomatedMG,
  title={Automated Movie Genre Classification with LDA-based Topic Modeling},
  author={Brandon Chao and Ankit Sirmorya},
  journal={International Journal of Computer Applications},
  year={2016},
  volume={145},
  pages={1-5}
}

@INPROCEEDINGS{Wang2018, author={H. {Wang} and H. {Zhang}}, booktitle={2018 IEEE 8th Annual Computing and Communication Workshop and Conference (CCWC)}, title={Movie genre preference prediction using machine learning for customer-based information}, year={2018}, volume={}, number={}, pages={110-116},}

@inproceedings{NetflixChallenge,
  added-at = {2011-05-26T12:27:17.000+0200},
  address = {New York},
  author = {Bennett, J. and Lanning, S.},
  biburl = {https://www.bibsonomy.org/bibtex/257ef9d0119acf19856b408297e5a2e5f/jaeschke},
  booktitle = {Proceedings of the KDD Cup Workshop 2007},
  interhash = {d03b540a69c3f6f282c6f302957c5f7f},
  intrahash = {57ef9d0119acf19856b408297e5a2e5f},
  keywords = {challenge netflix},
  month = aug,
  pages = {3--6},
  publisher = {ACM},
  timestamp = {2014-07-28T15:57:31.000+0200},
  title = {The Netflix Prize},
  url = {http://www.cs.uic.edu/~liub/KDD-cup-2007/NetflixPrize-description.pdf},
  year = 2007
}

@article{article,
author = {Koren, Yehuda},
year = {2009},
month = {09},
pages = {},
title = {The BellKor solution to the Netflix Grand Prize}
}

@article{WEHRMANN2017973,
title = "Movie genre classification: A multi-label approach based on convolutions through time",
journal = "Applied Soft Computing",
volume = "61",
pages = "973 - 982",
year = "2017",
issn = "1568-4946",
doi = "https://doi.org/10.1016/j.asoc.2017.08.029",
url = "http://www.sciencedirect.com/science/article/pii/S1568494617305112",
author = "Jônatas Wehrmann and Rodrigo C. Barros",
keywords = "Movie genre classification, Convolutional neural networks, Convolutions through time, Multi-label classification",
abstract = "The task of labeling movies according to their corresponding genre is a challenging classification problem, having in mind that genre is an immaterial feature that cannot be directly pinpointed in any of the movie frames. Hence, off-the-shelf image classification approaches are not capable of handling this task in a straightforward fashion. Moreover, movies may belong to multiple genres at the same time, making movie genre assignment a typical multi-label classification problem, which is per se much more challenging than standard single-label classification. In this paper, we propose a novel deep neural architecture based on convolutional neural networks (ConvNets) for performing multi-label movie-trailer genre classification. It encapsulates an ultra-deep ConvNet with residual connections, and it makes use of a special convolutional layer to extract temporal information from image-based features prior to performing the mapping of movie trailers to genres. We compare the proposed approach with the current state-of-the-art methods for movie classification that employ well-known image descriptors and other low-level handcrafted features. Results show that our method substantially outperforms the state-of-the-art for this task, improving classification performance for all movie genres."
}

@INPROCEEDINGS{Rasheed2002, author={Z. {Rasheed} and M. {Shah}}, booktitle={Object recognition supported by user interaction for service robots}, title={Movie genre classification by exploiting audio-visual features of previews}, year={2002}, volume={2}, number={}, pages={1086-1089 vol.2},}

@INPROCEEDINGS{Nam1998, author={J. {Nam} and M. {Alghoniemy} and A. H. {Tewfik}}, booktitle={Proceedings 1998 International Conference on Image Processing. ICIP98 (Cat. No.98CB36269)}, title={Audio-visual content-based violent scene characterization}, year={1998}, volume={1}, number={}, pages={353-357 vol.1},}

@INPROCEEDINGS{Ertugrul2018, author={A. M. {Ertugrul} and P. {Karagoz}}, booktitle={2018 IEEE 12th International Conference on Semantic Computing (ICSC)}, title={Movie Genre Classification from Plot Summaries Using Bidirectional LSTM}, year={2018}, volume={}, number={}, pages={248-251},}

@misc{mikolov2013efficient,
  abstract = {We propose two novel model architectures for computing continuous vector
representations of words from very large data sets. The quality of these
representations is measured in a word similarity task, and the results are
compared to the previously best performing techniques based on different types
of neural networks. We observe large improvements in accuracy at much lower
computational cost, i.e. it takes less than a day to learn high quality word
vectors from a 1.6 billion words data set. Furthermore, we show that these
vectors provide state-of-the-art performance on our test set for measuring
syntactic and semantic word similarities.},
  added-at = {2018-11-23T17:30:30.000+0100},
  author = {Mikolov, Tomas and Chen, Kai and Corrado, Greg and Dean, Jeffrey},
  biburl = {https://www.bibsonomy.org/bibtex/28b132b4b7e82cfb538fd462887ba98b8/florianpircher},
  description = {Efficient Estimation of Word Representations in Vector Space},
  interhash = {e92df552b17e9f952226a893b84ad739},
  intrahash = {8b132b4b7e82cfb538fd462887ba98b8},
  keywords = {final thema:sequence_labeling word_embedding},
  note = {cite arxiv:1301.3781},
  timestamp = {2018-11-27T09:35:06.000+0100},
  title = {Efficient Estimation of Word Representations in Vector Space},
  url = {http://arxiv.org/abs/1301.3781},
  year = 2013
}

@inproceedings{Peters2018,
  author={Peters, Matthew E. and  Neumann, Mark and Iyyer, Mohit and Gardner, Matt and Clark, Christopher and Lee, Kenton and Zettlemoyer, Luke},
  title={Deep contextualized word representations},
  booktitle={Proc. of NAACL},
  year={2018}
}